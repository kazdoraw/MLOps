{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023f3476",
   "metadata": {},
   "source": [
    "# Домашнее задание 1: ML Pipeline с DVC и MLflow\n",
    "\n",
    "## Цель\n",
    "Создание воспроизводимого ML-pipeline для классификации медицинских консультаций с использованием датасета ChatDoctor\n",
    "\n",
    "## Структура проекта\n",
    "```\n",
    "HW1/\n",
    "├── data/\n",
    "│   ├── raw/          # Исходные данные (DVC)\n",
    "│   └── processed/    # Обработанные данные (DVC)\n",
    "├── src/\n",
    "│   ├── prepare.py    # Подготовка данных\n",
    "│   └── train.py      # Обучение модели\n",
    "├── models/           # Сохраненные модели (DVC)\n",
    "├── dvc.yaml          # Описание пайплайна\n",
    "├── params.yaml       # Гиперпараметры\n",
    "└── requirements.txt  # Зависимости\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcc9ef3",
   "metadata": {},
   "source": [
    "## Шаг 1: Установка зависимостей\n",
    "\n",
    "Установим все необходимые библиотеки для работы с DVC, MLflow и ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2891fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pandas numpy scikit-learn mlflow dvc kagglehub joblib matplotlib seaborn pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e907d",
   "metadata": {},
   "source": [
    "## Шаг 2: Загрузка датасета ChatDoctor\n",
    "\n",
    "Загружаем датасет с Kaggle и сохраняем в папку data/raw/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b520b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cd85233",
   "metadata": {},
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "print(\"Загрузка датасета ChatDoctor...\")\n",
    "path = kagglehub.dataset_download(\"punyaslokaprusty/chatdoctor\")\n",
    "print(f\"Датасет загружен в: {path}\")\n",
    "\n",
    "files = os.listdir(path)\n",
    "print(f\"\\nФайлы в датасете: {files}\")\n",
    "\n",
    "for file in files:\n",
    "    source = os.path.join(path, file)\n",
    "    if os.path.isfile(source):\n",
    "        target = os.path.join(\"data/raw\", file)\n",
    "        shutil.copy(source, target)\n",
    "        print(f\"Скопирован: {file}\")\n",
    "        \n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(target, nrows=5)\n",
    "            print(f\"\\nСтруктура {file}:\")\n",
    "            print(f\"Колонки: {list(df.columns)}\")\n",
    "            print(f\"Размер: {pd.read_csv(target).shape}\")\n",
    "            print(f\"\\nПервые строки:\")\n",
    "            print(df.head(2))\n",
    "\n",
    "print(\"\\nДанные готовы к обработке!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ceb73d",
   "metadata": {},
   "source": [
    "## Шаг 2.1: Анализ структуры данных\n",
    "\n",
    "Изучаем структуру датасета для понимания формата и выбора стратегии обработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566c24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('.git'):\n",
    "    print(\"Инициализация Git...\")\n",
    "    !git init\n",
    "else:\n",
    "    print(\"Git репозиторий уже существует\")\n",
    "\n",
    "if not os.path.exists('.dvc'):\n",
    "    print(\"Инициализация DVC...\")\n",
    "    !dvc init\n",
    "    !git add .gitignore .dvc/config .dvc/.gitignore\n",
    "    !git commit -m \"Initialize Git and DVC\"\n",
    "else:\n",
    "    print(\"DVC уже инициализирован\")\n",
    "\n",
    "print(\"\\nGit и DVC готовы к работе!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b3960",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git init\n",
    "\n",
    "!dvc init\n",
    "\n",
    "!git add .gitignore .dvc/config .dvc/.gitignore\n",
    "!git commit -m \"Initialize Git and DVC\"\n",
    "\n",
    "print(\"\\nGit и DVC инициализированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78679513",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"data/raw/chatdoctor.csv\"):\n",
    "    !dvc add data/raw/chatdoctor.csv\n",
    "    !git add data/raw/chatdoctor.csv.dvc data/raw/.gitignore\n",
    "    !git commit -m \"Add raw dataset via DVC\"\n",
    "    print(\"\\nДатасет добавлен в DVC!\")\n",
    "    print(\"Создан файл data/raw/chatdoctor.csv.dvc с метаданными\")\n",
    "elif os.path.exists(\"data/raw\"):\n",
    "    csv_files = [f for f in os.listdir(\"data/raw\") if f.endswith('.csv')]\n",
    "    if csv_files:\n",
    "        target = f\"data/raw/{csv_files[0]}\"\n",
    "        !dvc add {target}\n",
    "        print(f\"\\nДатасет {csv_files[0]} добавлен в DVC!\")\n",
    "    else:\n",
    "        print(\"CSV файлы не найдены в data/raw/\")\n",
    "else:\n",
    "    print(\"Папка data/raw/ не существует. Сначала загрузите датасет.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc add data/raw/chatdoctor.csv\n",
    "\n",
    "!git add data/raw/chatdoctor.csv.dvc data/raw/.gitignore\n",
    "!git commit -m \"Add raw dataset via DVC\"\n",
    "\n",
    "print(\"\\nДатасет добавлен в DVC!\")\n",
    "print(\"Создан файл data/raw/chatdoctor.csv.dvc с метаданными\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc3750",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(\"dvc.yaml\"):\n",
    "    print(\"dvc.yaml уже существует. Используем существующий файл.\")\n",
    "    with open(\"dvc.yaml\", \"r\") as f:\n",
    "        print(\"\\nТекущее содержимое dvc.yaml:\")\n",
    "        print(f.read())\n",
    "else:\n",
    "    dvc_yaml_content = \"\"\"stages:\n",
    "  prepare:\n",
    "    cmd: python src/prepare.py\n",
    "    deps:\n",
    "      - src/prepare.py\n",
    "      - data/raw/chatdoctor.csv\n",
    "    params:\n",
    "      - prepare.test_size\n",
    "      - prepare.random_state\n",
    "      - prepare.sample_size\n",
    "    outs:\n",
    "      - data/processed/train.csv\n",
    "      - data/processed/test.csv\n",
    "\n",
    "  train:\n",
    "    cmd: python src/train.py\n",
    "    deps:\n",
    "      - src/train.py\n",
    "      - data/processed/train.csv\n",
    "      - data/processed/test.csv\n",
    "    params:\n",
    "      - train.model_type\n",
    "      - train.n_estimators\n",
    "      - train.max_depth\n",
    "      - train.random_state\n",
    "      - train.max_features\n",
    "    outs:\n",
    "      - models/model.pkl\n",
    "\"\"\"\n",
    "    \n",
    "    with open(\"dvc.yaml\", \"w\") as f:\n",
    "        f.write(dvc_yaml_content)\n",
    "    \n",
    "    print(\"Файл dvc.yaml создан!\")\n",
    "    print(\"\\nСодержимое:\")\n",
    "    print(dvc_yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad14586",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc_yaml_content = \"\"\"stages:\n",
    "  prepare:\n",
    "    cmd: python src/prepare.py\n",
    "    deps:\n",
    "      - src/prepare.py\n",
    "      - data/raw/chatdoctor.csv\n",
    "    params:\n",
    "      - prepare.test_size\n",
    "      - prepare.random_state\n",
    "      - prepare.sample_size\n",
    "    outs:\n",
    "      - data/processed/train.csv\n",
    "      - data/processed/test.csv\n",
    "\n",
    "  train:\n",
    "    cmd: python src/train.py\n",
    "    deps:\n",
    "      - src/train.py\n",
    "      - data/processed/train.csv\n",
    "      - data/processed/test.csv\n",
    "    params:\n",
    "      - train.model_type\n",
    "      - train.n_estimators\n",
    "      - train.max_depth\n",
    "      - train.random_state\n",
    "      - train.max_features\n",
    "    outs:\n",
    "      - models/model.pkl\n",
    "\"\"\"\n",
    "\n",
    "with open(\"dvc.yaml\", \"w\") as f:\n",
    "    f.write(dvc_yaml_content)\n",
    "\n",
    "print(\"Файл dvc.yaml создан!\")\n",
    "print(\"\\nСодержимое:\")\n",
    "print(dvc_yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2497ae3",
   "metadata": {},
   "source": [
    "## Шаг 6: Запуск DVC пайплайна\n",
    "\n",
    "Запускаем полный пайплайн: prepare → train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc repro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a54d8",
   "metadata": {},
   "source": [
    "## Шаг 7: Версионирование обработанных данных и модели\n",
    "\n",
    "Добавляем в DVC обработанные данные и модель, фиксируем изменения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ffbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add dvc.yaml dvc.lock params.yaml requirements.txt README.md .gitignore\n",
    "!git add src/prepare.py src/train.py\n",
    "!git add data/processed/.gitignore models/.gitignore\n",
    "!git add data/processed/train.csv.dvc data/processed/test.csv.dvc models/model.pkl.dvc\n",
    "\n",
    "!git commit -m \"Add DVC pipeline with prepare and train stages\"\n",
    "\n",
    "print(\"\\nВсе изменения закоммичены в Git!\")\n",
    "print(\"Метаданные данных и модели под контролем DVC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65640e",
   "metadata": {},
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.makedirs(\"../dvc-storage\", exist_ok=True)\n",
    "\n",
    "result = subprocess.run(['dvc', 'remote', 'list'], capture_output=True, text=True)\n",
    "\n",
    "if 'localstorage' not in result.stdout:\n",
    "    !dvc remote add -d localstorage ../dvc-storage\n",
    "    print(\"DVC remote 'localstorage' добавлен\")\n",
    "else:\n",
    "    print(\"DVC remote 'localstorage' уже существует\")\n",
    "\n",
    "!dvc push\n",
    "\n",
    "!git add .dvc/config\n",
    "!git commit -m \"Configure DVC remote storage\" --allow-empty\n",
    "\n",
    "print(\"\\nDVC remote storage настроен!\")\n",
    "print(\"Данные и модели загружены в ../dvc-storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"../dvc-storage\", exist_ok=True)\n",
    "\n",
    "!dvc remote add -d localstorage ../dvc-storage\n",
    "!dvc push\n",
    "\n",
    "!git add .dvc/config\n",
    "!git commit -m \"Configure DVC remote storage\"\n",
    "\n",
    "print(\"\\nDVC remote storage настроен!\")\n",
    "print(\"Данные и модели загружены в ../dvc-storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed69e9",
   "metadata": {},
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "print(\"Для просмотра MLflow UI выполните в терминале:\")\n",
    "print(\"\\n  mlflow ui --backend-store-uri sqlite:///mlflow.db\")\n",
    "print(\"\\nЗатем откройте в браузере: http://127.0.0.1:5000\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "try:\n",
    "    experiments = mlflow.search_experiments()\n",
    "    print(\"\\nДоступные эксперименты:\")\n",
    "    for exp in experiments:\n",
    "        print(f\"  - {exp.name} (ID: {exp.experiment_id})\")\n",
    "    \n",
    "    runs = mlflow.search_runs(experiment_names=[\"chatdoctor_classification\"])\n",
    "    if not runs.empty:\n",
    "        print(f\"\\nЗапущено экспериментов: {len(runs)}\")\n",
    "        print(\"\\nПоследний эксперимент:\")\n",
    "        latest = runs.iloc[0]\n",
    "        print(f\"  Accuracy (test):  {latest.get('metrics.accuracy_test', 'N/A')}\")\n",
    "        print(f\"  Precision:        {latest.get('metrics.precision', 'N/A')}\")\n",
    "        print(f\"  Recall:           {latest.get('metrics.recall', 'N/A')}\")\n",
    "        print(f\"  F1-score:         {latest.get('metrics.f1_score', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"\\nЭксперименты еще не запущены. Запустите: dvc repro\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nОшибка при чтении MLflow: {e}\")\n",
    "    print(\"Возможно, эксперименты еще не запущены.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0590927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "print(\"Для просмотра MLflow UI выполните в терминале:\")\n",
    "print(\"\\n  mlflow ui --backend-store-uri sqlite:///mlflow.db\")\n",
    "print(\"\\nЗатем откройте в браузере: http://127.0.0.1:5000\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "experiments = mlflow.search_experiments()\n",
    "print(\"\\nДоступные эксперименты:\")\n",
    "for exp in experiments:\n",
    "    print(f\"  - {exp.name} (ID: {exp.experiment_id})\")\n",
    "\n",
    "runs = mlflow.search_runs(experiment_names=[\"chatdoctor_classification\"])\n",
    "if not runs.empty:\n",
    "    print(f\"\\nЗапущено экспериментов: {len(runs)}\")\n",
    "    print(\"\\nПоследний эксперимент:\")\n",
    "    latest = runs.iloc[0]\n",
    "    print(f\"  Accuracy:  {latest['metrics.accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {latest['metrics.precision']:.4f}\")\n",
    "    print(f\"  Recall:    {latest['metrics.recall']:.4f}\")\n",
    "    print(f\"  F1-score:  {latest['metrics.f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704e4630",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "print(\"Проверка структуры проекта:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "required_files = [\n",
    "    \"dvc.yaml\",\n",
    "    \"params.yaml\",\n",
    "    \"requirements.txt\",\n",
    "    \"README.md\",\n",
    "    \".gitignore\",\n",
    "    \"src/prepare.py\",\n",
    "    \"src/train.py\"\n",
    "]\n",
    "\n",
    "for file in required_files:\n",
    "    exists = \"✓\" if os.path.exists(file) else \"✗\"\n",
    "    print(f\"{exists} {file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nПроект готов к публикации!\")\n",
    "print(\"\\nДля воспроизведения на другой машине:\")\n",
    "print(\"  1. git clone https://github.com/kazdoraw/MLOps.git\")\n",
    "print(\"  2. cd MLOps/HW1\")\n",
    "print(\"  3. pip install -r requirements.txt\")\n",
    "print(\"  4. dvc pull\")\n",
    "print(\"  5. dvc repro\")\n",
    "print(\"\\nMLflow UI:\")\n",
    "print(\"  mlflow ui --backend-store-uri sqlite:///mlflow.db\")\n",
    "print(\"\\n✅ Проект уже на GitHub: https://github.com/kazdoraw/MLOps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Итоги и оптимизация для MacBook Pro M4\n",
    "\n",
    "### Реализованная задача\n",
    "**Бинарная классификация медицинских консультаций:**\n",
    "- Класс 0: Консультация решается онлайн\n",
    "- Класс 1: Требуется офлайн-визит к врачу\n",
    "\n",
    "### ML Pipeline\n",
    "1. **prepare.py**: Парсинг данных ChatDoctor, автогенерация меток, train/test split\n",
    "2. **train.py**: TF-IDF + RandomForest, логирование метрик в MLflow\n",
    "3. **dvc.yaml**: Автоматизация через `dvc repro`\n",
    "\n",
    "### Оптимизация для M4\n",
    "- `n_jobs=-1`: использование всех ядер CPU\n",
    "- TF-IDF max_features=5000: баланс качества и скорости\n",
    "- Sample size 10000: быстрое обучение для экспериментов\n",
    "- `max_depth=15`: предотвращение переобучения\n",
    "\n",
    "### Альтернативные модели для M4\n",
    "- **LogisticRegression**: быстрая, хорошо работает с текстом\n",
    "- **SGDClassifier**: для очень больших датасетов\n",
    "- **ComplementNB**: эффективен для несбалансированных классов\n",
    "\n",
    "### Проект на GitHub\n",
    "✅ **Репозиторий**: https://github.com/kazdoraw/MLOps.git\n",
    "\n",
    "### Следующие шаги\n",
    "1. Экспериментировать с параметрами через `params.yaml`\n",
    "2. Настроить удаленное DVC remote (S3/GCS)\n",
    "3. Добавить evaluate стадию (опционально)\n",
    "4. Попробовать другие модели (LogisticRegression, SGDClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea81f0",
   "metadata": {},
   "source": [
    "## Итоги и оптимизация для MacBook Pro M4\n",
    "\n",
    "### Реализованная задача\n",
    "**Бинарная классификация медицинских консультаций:**\n",
    "- Класс 0: Консультация решается онлайн\n",
    "- Класс 1: Требуется офлайн-визит к врачу\n",
    "\n",
    "### ML Pipeline\n",
    "1. **prepare.py**: Парсинг данных ChatDoctor, автогенерация меток, train/test split\n",
    "2. **train.py**: TF-IDF + RandomForest, логирование метрик в MLflow\n",
    "3. **dvc.yaml**: Автоматизация через `dvc repro`\n",
    "\n",
    "### Оптимизация для M4\n",
    "- `n_jobs=-1`: использование всех ядер CPU\n",
    "- TF-IDF max_features=5000: баланс качества и скорости\n",
    "- Sample size 10000: быстрое обучение для экспериментов\n",
    "- `max_depth=15`: предотвращение переобучения\n",
    "\n",
    "### Альтернативные модели для M4\n",
    "- **LogisticRegression**: быстрая, хорошо работает с текстом\n",
    "- **SGDClassifier**: для очень больших датасетов\n",
    "- **ComplementNB**: эффективен для несбалансированных классов\n",
    "\n",
    "### Следующие шаги\n",
    "1. Загрузить в GitHub\n",
    "2. Настроить DVC remote (локальный или S3)\n",
    "3. Экспериментировать с параметрами через `params.yaml`\n",
    "4. Добавить evaluate стадию (опционально)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
