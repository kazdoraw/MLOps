## Домашнее задание 1. Создание воспроизводимого ML-pipeline с использованием DVC и MLflow

Задание выполняется в рамках модуля 1 «Основы воспроизводимого машинного обучения. Жизненный цикл MLOps». Формат выполнения — индивидуальная работа.

Работать необходимо в локальной среде (VS Code, PyCharm или Jupyter Notebook) с использованием Git, DVC, MLflow.

Форма сдачи — ссылка на публичный Git-репозиторий (GitHub, GitLab и т. д.) с корректно оформленным README и структурой проекта в форме для сдачи ДЗ.

#### Цели задания

Задание направлено на построение минимального, но полноценного MLOps-контура, обеспечивающего:

- воспроизводимость экспериментов;
- контроль версий данных и моделей;
- автоматизацию процесса обучения и оценки модели;
- документирование процесса через DVC и MLflow.

После выполнения студент:

- освоит базовые принципы структурирования ML-проекта;
- научится использовать DVC для версионирования данных и пайплайнов;
- сможет логировать эксперименты в MLflow (метрики, параметры, артефакты);
- создаст воспроизводимую среду для запуска обучения одной командой;
- оформит понятный и воспроизводимый репозиторий с ML-проектом.

#### Как выполнять задание

**Шаг 1. Подготовка среды и структуры проекта.** Создайте новый Git-репозиторий с понятной структурой:

├── data/ # Сырые и обработанные данные (только через DVC)

├── src/ # Скрипты (prepare.py, train.py)

├── dvc.yaml # Описание пайплайна

├── params.yaml # Гиперпараметры

├── requirements.txt # Зависимости

└── README.md # Документация

Для этого:

1. Инициализируйте Git и DVC:  
    `git init   dvc init`
2. Добавьте небольшой датасет (например, Iris, Titanic или Wine). Важно: не храните CSV в Git, используйте DVC:  
    `dvc add data/raw/data.csv`
    
    git add data/.gitignore data/raw.dvc
    git commit -m "Add dataset via DVC"
    

**Шаг 2. Создание пайплайна DVC:**

- Определите минимум две стадии:

- prepare — подготовка данных: сплит на train/test, базовая очистка и сохранение;
- train — обучение модели (логистическая регрессия, random forest и т. п.).

- Создайте dvc.yaml:  
      
    
    dvc run -n prepare -d src/prepare.py -o data/processed python src/prepare.py
    dvc run -n train -d src/train.py -d data/processed -o model.pkl python src/train.py
    
- Добавьте params.yaml для управления параметрами (например, split_ratio, n_estimators, random_state).

**Шаг 3. Логирование экспериментов в MLflow:**

- Поднимите локальный трекинг-сервер MLflow:  
      
    `mlflow ui --backend-store-uri sqlite:///mlflow.db`

- В коде обучения добавьте логирование:  
      
    `import mlflow`
    
    mlflow.log_param("model", "LogisticRegression")
    mlflow.log_metric("accuracy", acc)
    mlflow.log_artifact("model.pkl")
    

Убедитесь, что параметры, метрики и артефакты отображаются в UI MLflow.

**Шаг 4. Проверка воспроизводимости.** Проверьте, что проект можно полностью воспроизвести:

git clone <repo>
cd <repo>
pip install -r requirements.txt
dvc pull
dvc repro

Результат: модель обучается и выдает те же метрики при фиксированных seed и версиях библиотек.

**Шаг 5. По желанию (не на оценку).** Если хотите попробовать сделать что-то еще, то добавьте одно из следующих улучшений:

- Стадия Evaluate или Register (лог модели в Model Registry).
- Контейнеризация проекта (Dockerfile).
- Проверки данных (Great Expectations / Pytest).
- CI/CD-пайплайн для автоматического обучения.

#### Формат сдачи и отправка задания

**Работа сдается в виде ссылки на Git-репозиторий, содержащий:**

- Структуру проекта (см. выше).
- Корректный dvc.yaml, params.yaml, requirements.txt.
- Код для prepare.py, train.py.
- Aртефакты, версионируемые через DVC.
- README.md со следующими разделами:

1. Цель проекта.
2. Как запустить (3–6 команд).
3. Краткое описание пайплайна.
4. Где смотреть UI MLflow.

**Рекомендуемое имя репозитория:** mlops_hw1_<Фамилия>_<Имя>

#### Критерии оценки

|   |   |
|---|---|
|**Критерии**|**Баллы**|
|**Критерий 1. Структура репозитория и документация**|   |
|Репозиторий неструктурирован, отсутствует README или он не содержит инструкции по запуску|0|
|Репозиторий частично структурирован (например, есть код и данные, но отсутствует описание пайплайна или порядок запуска)|1|
|Репозиторий корректно оформлен: есть README с инструкциями (3–6 команд), структура соответствует требованиям (src/, data/, dvc.yaml, params.yaml), указано, где запустить MLflow|2|
|**Критерий 2. Версионирование данных через DVC**|   |
|DVC не используется, данные загружены напрямую в Git или отсутствует контроль версий данных|0|
|DVC инициализирован, но данные не добавлены в хранилище (dvc add не выполнен) или отсутствует удаленное хранилище|1|
|Данные корректно версионируются через DVC: используется dvc add, есть .dvc-файлы, подключено хранилище и добавлены в .gitignore|2|
|**Критерий 3. Автоматизация пайплайна (dvc.yaml)**|   |
|dvc.yaml отсутствует или пайплайн не воспроизводим|0|
|Пайплайн частично реализован (только одна стадия или неверно указаны зависимости/артефакты)|1|
|Пайплайн реализован корректно: минимум две стадии (prepare, train), зависимости и выходы прописаны, dvc repro работает|2|
|**Критерий 4. Логирование экспериментов в MLflow**|   |
|MLflow не используется, параметры и метрики не логируются|0|
|MLflow настроен частично (например, логируются только параметры или метрики без артефактов)|1|
|Полное логирование: параметры, метрики и артефакты (модель, графики) логируются, есть локальный MLflow Tracking UI|2|
|**Критерий 5. Воспроизводимость эксперимента (dvc repro)**|   |
|Запуск пайплайна невозможен, отсутствуют зависимости или инструкции|0|
|Запуск частично воспроизводим: отдельные шаги выполняются, но не достигается полный цикл обучения|1|
|Полная воспроизводимость: после git clone, dvc pull, dvc repro модель обучается и выдает стабильные метрики|2|


import kagglehub

# Download latest version
path = kagglehub.dataset_download("punyaslokaprusty/chatdoctor")

print("Path to dataset files:", path)


